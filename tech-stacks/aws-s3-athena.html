<!DOCTYPE html>
<html lang="en">
<head>
    <title>Data Mesh Architecture: AWS S3 and Athena</title>
    <meta charset="utf-8">
    <meta name="description" content="How to build a data mesh architecture with AWS S3 and Athena" />
    <meta name="keywords" content="data mesh, data mesh architecture, domain-driven data analytics, data analytics, domain-driven design, domain ownership, data as a product, data product, federated governance, self-serve data platform, data platform">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:site" content="@innoq" />
    <meta name="twitter:title" content="Data Mesh Architecture: AWS S3 and Athena" />
    <meta name="twitter:description" content="How to build a data mesh architecture with AWS S3 and Athena" />
    <meta name="twitter:image" content="https://www.datamesh-architecture.com/images/aws-s3-athena_card.png" />
    <meta name="twitter:image:alt" content="Data Mesh Architecture: Domains are in the center and teams do analytics on their own. They build and interconnect with data products. A data platform team and a enablement team help. Global policies are agreed through federated governance." />
    <meta property="og:url" content="https://datamesh-architecture.com" />
    <meta property="og:title" content="Data Mesh Architecture: AWS S3 and Athena" />
    <meta property="og:description" content="How to build a data mesh architecture with AWS S3 and Athena" />
    <meta property="og:image" content="https://www.datamesh-architecture.com/images/aws-s3-athena_card.png" />

    <link rel="preload" as="font" type="font/woff2" href="https://www.innoq.com/assets/MarkPro-Book.woff2?cachebuster=2" crossorigin="">
    <link rel="preload" as="font" type="font/woff2" href="https://www.innoq.com/assets/MarkPro-Bold.woff2?cachebuster=2" crossorigin="">
    <link rel="preload" as="font" type="font/woff2" href="https://www.innoq.com/assets/MarkPro-Heavy.woff2?cachebuster=2" crossorigin="">
    <link rel="stylesheet" href="../css/style.css" />
    <link rel="stylesheet" href="../css/0.9.3_css_bulma.css" />
    <link rel="stylesheet" href="../css/font-awesome_6.0.0_css_all.css"/>
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico">
</head>
<body>
<div class="container">

    <section class="section">

        <nav class="breadcrumb" aria-label="breadcrumbs">
            <ul>
                <li><a href="https://www.datamesh-architecture.com/">Data Mesh Architecture</a></li>
                <li><a href="https://www.datamesh-architecture.com/#tech-stacks">Tech Stacks</a></li>
                <li class="is-active"><a href="#" aria-current="page">AWS S3 and Athena</a></li>
            </ul>
        </nav>

        <h1 class="title">AWS S3 and Athena</h1>

        <div class="notification is-info is-light">
            Data mesh is primarily an organizational approach, and that's why you can't buy a data mesh from a vendor. Technology, however, is important still as it acts as an enabler for data mesh, and only useful and easy to use solutions will lead to domain teams' acceptance. The available offerings of cloud providers already provide a sufficient set of good self-serve data services to let you form a data platform for your data mesh. We want to show which services can be used to get started.
        </div>

        <div class="content">
            <p>
                We often see Data Mesh implementations relying on <strong>AWS S3 and Athena</strong> as the primary means to share and query data products.
            </p>
            <img src="../images/aws-s3-athena.png.webp" alt="Data Mesh Architecture with AWS S3 and Athena" style="width: 100%">
            <p>
                Interestingly enough, most data mesh implementations on AWS are using S3 and Athena,
                and not Redshift, which would be more the equivalent to <a
                    href="google-cloud-bigquery.html">Googleâ€™s BigQuery approach</a>.
                We assume this is mainly because S3 and Athena are more simple to use, serverless,
                and billed on a pay-per-use basis, without the need to provision clusters
                upfront.</p>

            <div class="columns">
                <div class="column">
                    <p>
                        <strong>AWS S3</strong> is the central component for storing analytical data.
                        S3 is a simple file based object store and data can be stored in many different formats, such as CSV, JSON, Avro, or Parquet.
                        S3 buckets are used for all stages: raw files, aggregated data, and data products.
                        Metadata and queries are often stored as S3 files, as well.
                        All data relevant AWS services and most independent software product have an interface to S3, either as a sink or as a source.
                        <strong>AWS Athena</strong> supports querying multiple JSON files stored in different S3 buckets.
                    </p>
                    <p>
                        Every domain team typically has their <strong>own AWS S3 buckets</strong> to store their own data products, either on a shared AWS account or in a team AWS account.
                    </p>

                </div>
                <div class="column">
                    <figure class="image">
                        <img src="../images/aws-athena-s3.png.webp" alt="Screenshot of S3 files">
                    </figure>
                </div>
            </div>
            <div class="columns">
                <div class="column">
                    <p>
                        Analytical queries are executed through <strong>Athena</strong> that queries S3 files and other datasets with standard SQL and performs cross-dataset join operations.
                        Athena uses <em>Presto</em>, a distributed query engine.
                        Athena works directly on S3 files without the need to import data first, but it requires to know the schema of the files,
                        so metadata need to be defined first, either manually, or by using AWS Glue Data Catalog which can crawl files to infer the structure.
                    </p>
                </div>
                <div class="column">
                    <figure class="image">
                        <img src="../images/aws-athena.png.webp" alt="Screenshot of Athena">
                    </figure>
                </div>
            </div>
            <div class="columns">
                <div class="column">
                    <p>
                        AWS has a number of different solutions to build data pipelines for cleaning, pre-processing and transforming S3 files.
                        A serverless approach is to use <strong>AWS Glue ETL</strong>, which executes Spark or Python scripts and schedules jobs.
                        The AWS Glue Studio also provides a visual editor to build and manage ETL scripts.
                    </p>
                </div>
                <div class="column">
                    <figure class="image">
                        <img src="../images/aws-glue-studio.png.webp" alt="Screenshot of Glue Studio Editor">
                    </figure>
                </div>
            </div>
            <div class="columns">
                <div class="column">
                    <p>
                        <strong>Amazon QuickSight</strong> is the data visualization tool provided by Amazon.
                        It uses an in-memory cache, called <em>SPICE</em> that allows quick calculations and aggregations, once the data is imported.
                    </p>
                </div>
                <div class="column">
                    <figure class="image">
                        <img src="../images/aws-quicksight.png.webp" alt="Screenshot of Quicksight">
                    </figure>
                </div>
            </div>
            <div class="columns">
                <div class="column">
                    <p>
                        Governance, Data Catalog, and even policy automation can be implemented through
                        <strong>AWS Lake Formation</strong>.
                        In Lake Formation S3 locations from different AWS accounts can be linked.
                        The data in S3 files can be documented in the Data Catalog, including the data schema.
                        Data sets can be tagged with special <em>LF-Tags</em> to give table and columnar-level permissions.
                        Data loss prevention can be automated by enabling <strong>Macie</strong> to continuously scan S3 buckets for sensitive data and potentially unwanted data exposures.
                    </p>
                </div>
                <div class="column">
                    <figure class="image">
                        <img src="../images/aws-lakeformation.png.webp" alt="Screenshot of Lakeformation">
                    </figure>
                </div>
            </div>

            <h5>References</h5>
            <ul>
                <li><a href="https://aws.amazon.com/blogs/big-data/design-a-data-mesh-architecture-using-aws-lake-formation-and-aws-glue/">https://aws.amazon.com/blogs/big-data/design-a-data-mesh-architecture-using-aws-lake-formation-and-aws-glue/</a></li>
            </ul>

        </div>
    </section>

</div>

<footer class="footer">
    <div class="content has-text-centered">
        <p>
            <a href="https://www.innoq.com">
                <img src="/images/supported-by-innoq--petrol-apricot.svg" alt="Supported by INNOQ" class="footer-logo" width="180" />
            </a>
        </p>
        <p>
            <a href="https://www.innoq.com/en/impressum/">Legal Notice</a>
            &nbsp
            <a href="https://www.innoq.com/en/datenschutz/">Privacy</a>
        </p>
    </div>
</footer>

<script async defer src="https://scripts.simpleanalyticscdn.com/latest.js"></script>
<noscript><img src="https://queue.simpleanalyticscdn.com/noscript.gif" alt="" referrerpolicy="no-referrer-when-downgrade" /></noscript>

<link rel="stylesheet" href="css/glightbox.css" />
<script src="js/glightbox.js"></script>
<script type="text/javascript">
  const lightbox = GLightbox({});
</script>


<script src="js/anchor.min.js"></script>
<script>anchors.add();</script>
</body>

</html>
